{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"ms-latent-dim-256-train.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wGPQBbYHsY0P","executionInfo":{"status":"ok","timestamp":1602341934353,"user_tz":-480,"elapsed":753,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from pylab import rcParams"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"kCYolQHR_3g3","executionInfo":{"status":"ok","timestamp":1602341942380,"user_tz":-480,"elapsed":7478,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"d9aa50f2-523f-43bd-dc7d-4cda18deca8f","colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-PGTRNq1sY0W"},"source":["# Load Dataset"]},{"cell_type":"code","metadata":{"id":"578-Vzh0sfhk","executionInfo":{"status":"ok","timestamp":1602341944970,"user_tz":-480,"elapsed":864,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"60189e97-ad7e-42f8-c1a1-bc35cba897b2","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6c1du9kkvo74","executionInfo":{"status":"ok","timestamp":1602341945284,"user_tz":-480,"elapsed":771,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"94d2f9bf-2dcc-4cdf-a111-335d5f3bdc36","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd '/content/drive/My Drive/VIP_Project'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/VIP_Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eWzhZ5XkxGFr","executionInfo":{"status":"error","timestamp":1602341641446,"user_tz":-480,"elapsed":46821,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"2653b182-7b38-4618-daea-f2061b79b226","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#!pip install tensorflow==2.3\n","#tf.__version__"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/ae/0b08f53498417914f2274cc3b5576d2b83179b0cbb209457d0fde0152174/tensorflow-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n","\u001b[K     |████████████████████████████████| 320.4MB 51kB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.35.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.32.0)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (2.3.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.12.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.1.0)\n","Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.4.1)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (2.10.0)\n","Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.18.5)\n","Collecting tensorboard<3,>=2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/1b/6a420d7e6ba431cf3d51b2a5bfa06a958c4141e3189385963dc7f6fbffb6/tensorboard-2.3.0-py3-none-any.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 47.1MB/s \n","\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.3.3)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (3.3.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.6.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.15.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (1.1.2)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.3) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow==2.3) (39.1.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (3.2.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.17.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.7.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (2.0.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.2.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2020.6.20)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.2.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.8)\n","\u001b[31mERROR: tensorboard 2.3.0 has requirement setuptools>=41.0.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, tensorflow\n","  Found existing installation: tensorboard 1.9.0\n","    Uninstalling tensorboard-1.9.0:\n","      Successfully uninstalled tensorboard-1.9.0\n","  Found existing installation: tensorflow 1.9.0\n","    Uninstalling tensorflow-1.9.0:\n","      Successfully uninstalled tensorflow-1.9.0\n","Successfully installed tensorboard-2.3.0 tensorflow-2.3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorflow"]}}},"metadata":{"tags":[]}},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-86433a56b686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install tensorflow==2.3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"cell_type":"code","metadata":{"id":"AoIByisqsY0Y","executionInfo":{"status":"ok","timestamp":1602342025923,"user_tz":-480,"elapsed":77300,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"c2ab6885-61f5-4ef7-e4db-79dfd394fb3b","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["num_epoch = 100\n","batch_size = 10\n","\n","in_timesteps  = range(0,19)\n","out_timesteps = range(1,20)\n","\n","data = np.load( \"moving-shapes-2-tr-images.npy\" )\n","\n","# training set\n","x_tr = data[:5000,in_timesteps]\n","y_tr = data[:5000,out_timesteps]\n","\n","# validation set\n","x_te = data[5000:6000,in_timesteps]\n","y_te = data[5000:6000,out_timesteps]\n","\n","print (np.shape(x_tr), np.shape(y_tr), np.shape(x_te), np.shape(y_te))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(5000, 19, 64, 64, 3) (5000, 19, 64, 64, 3) (1000, 19, 64, 64, 3) (1000, 19, 64, 64, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4WFOsxzxsY0d"},"source":["# Define Parameters"]},{"cell_type":"code","metadata":{"id":"-53ETC-4sY0e","executionInfo":{"status":"ok","timestamp":1602342033056,"user_tz":-480,"elapsed":1449,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"ffb1bc65-4f1a-4812-adee-a1f5b37d2983","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["lstm_units = 1024\n","feature_vector = 1024\n","latent_dim = 256\n","\n","# placeholders to hold each frame\n","x_ = tf.placeholder(\"float\", shape= (None, len(in_timesteps),  64, 64, 3))\n","y_ = tf.placeholder(\"float\", shape= (None, len(out_timesteps), 64, 64, 3))\n","\n","# encoder\n","encoder_conv1_w = tf.get_variable(\"encoder_conv1_w\", shape=[7, 7, 3, 16])\n","encoder_conv2_w = tf.get_variable(\"encoder_conv2_w\", shape=[5, 5, 16, 32])\n","encoder_conv3_w = tf.get_variable(\"encoder_conv3_w\", shape=[5, 5, 32, 48])\n","encoder_conv4_w = tf.get_variable(\"encoder_conv4_w\", shape=[3, 3, 48, 64])\n","\n","encoder_conv1_b = tf.get_variable(\"encoder_conv1_b\", shape=[16])\n","encoder_conv2_b = tf.get_variable(\"encoder_conv2_b\", shape=[32])\n","encoder_conv3_b = tf.get_variable(\"encoder_conv3_b\", shape=[48])\n","encoder_conv4_b = tf.get_variable(\"encoder_conv4_b\", shape=[64])\n","\n","def encoder(x):\n","    out = tf.nn.conv2d(input=x,   filter=encoder_conv1_w, strides=[1, 2, 2, 1], padding='SAME') + encoder_conv1_b\n","    out = tf.nn.relu(out)\n","    out = tf.nn.conv2d(input=out, filter=encoder_conv2_w, strides=[1, 2, 2, 1], padding='SAME') + encoder_conv2_b\n","    out = tf.nn.relu(out)\n","    out = tf.nn.conv2d(input=out, filter=encoder_conv3_w, strides=[1, 2, 2, 1], padding='SAME') + encoder_conv3_b\n","    out = tf.nn.relu(out)\n","    out = tf.nn.conv2d(input=out, filter=encoder_conv4_w, strides=[1, 2, 2, 1], padding='SAME') + encoder_conv4_b\n","    out = tf.nn.relu(out)\n","    out = tf.reshape(out, shape=[-1, 4*4*64])\n","    return out\n","\n","# decoder\n","decoder_conv1_w = tf.get_variable(\"decoder_conv1_w\", shape=[3, 3, 48, 64])\n","decoder_conv2_w = tf.get_variable(\"decoder_conv2_w\", shape=[5, 5, 32, 48])\n","decoder_conv3_w = tf.get_variable(\"decoder_conv3_w\", shape=[5, 5, 16, 32])\n","decoder_conv4_w = tf.get_variable(\"decoder_conv4_w\", shape=[7, 7, 3, 16])\n","\n","decoder_conv1_b = tf.get_variable(\"decoder_conv1_b\", shape=[48])\n","decoder_conv2_b = tf.get_variable(\"decoder_conv2_b\", shape=[32])\n","decoder_conv3_b = tf.get_variable(\"decoder_conv3_b\", shape=[16])\n","decoder_conv4_b = tf.get_variable(\"decoder_conv4_b\", shape=[3])\n","\n","def decoder(x):\n","    out = tf.reshape(x, shape=[-1, 4, 4, 64])\n","    out = tf.nn.conv2d_transpose(out, filter=decoder_conv1_w, strides=[1, 2, 2, 1], output_shape=[batch_size, 8, 8, 48], padding='SAME') + decoder_conv1_b\n","    out = tf.nn.relu(out)\n","    out = tf.nn.conv2d_transpose(out, filter=decoder_conv2_w, strides=[1, 2, 2, 1], output_shape=[batch_size, 16, 16, 32], padding='SAME') + decoder_conv2_b\n","    out = tf.nn.relu(out)\n","    out = tf.nn.conv2d_transpose(out, filter=decoder_conv3_w, strides=[1, 2, 2, 1], output_shape=[batch_size, 32, 32, 16], padding='SAME') + decoder_conv3_b\n","    out = tf.nn.relu(out)\n","    out = tf.nn.conv2d_transpose(out, filter=decoder_conv4_w, strides=[1, 2, 2, 1], output_shape=[batch_size, 64, 64, 3], padding='SAME') + decoder_conv4_b\n","    out = tf.nn.sigmoid(out)\n","    return out\n","\n","# f_posterior\n","f_posterior_fc1_w = tf.get_variable(\"phi_enc_fc1_w\", shape=[feature_vector+lstm_units, latent_dim])\n","f_posterior_fc2_w = tf.get_variable(\"phi_enc_fc2_w\", shape=[latent_dim, latent_dim])\n","\n","f_posterior_fc1_b = tf.get_variable(\"phi_enc_fc1_b\", shape=[latent_dim])\n","f_posterior_fc2_b = tf.get_variable(\"phi_enc_fc2_b\", shape=[latent_dim])\n","\n","f_posterior_mu_w = tf.get_variable(\"phi_enc_mu_w\", shape=[latent_dim, latent_dim])\n","f_posterior_mu_b = tf.get_variable(\"phi_enc_mu_b\", shape=[latent_dim])\n","\n","f_posterior_sigma_w = tf.get_variable(\"phi_enc_sigma_w\", shape=[latent_dim, latent_dim])\n","f_posterior_sigma_b = tf.get_variable(\"phi_enc_sigma_b\", shape=[latent_dim])\n","\n","def f_posterior(out):\n","    out = tf.matmul(out, f_posterior_fc1_w) + f_posterior_fc1_b    \n","    out = tf.nn.relu(out)\n","    out = tf.matmul(out, f_posterior_fc2_w) + f_posterior_fc2_b\n","    out = tf.nn.relu(out)\n","    \n","    out_mu  = tf.matmul(out, f_posterior_mu_w)  + f_posterior_mu_b\n","    out_std = tf.nn.softplus(tf.matmul(out, f_posterior_sigma_w) + f_posterior_sigma_b)\n","    \n","    return out_mu, out_std\n","\n","# f_decoder\n","f_decoder_fc1_w = tf.get_variable(\"phi_dec_fc1_w\", shape=[latent_dim+lstm_units, feature_vector])\n","f_decoder_fc2_w = tf.get_variable(\"phi_dec_fc2_w\", shape=[feature_vector, feature_vector])\n","\n","f_decoder_fc1_b = tf.get_variable(\"phi_dec_fc1_b\", shape=[feature_vector])\n","f_decoder_fc2_b = tf.get_variable(\"phi_dec_fc2_b\", shape=[feature_vector])\n","\n","def f_decoder(out):\n","    out = tf.matmul(out, f_decoder_fc1_w) + f_decoder_fc1_b\n","    out = tf.nn.relu(out)\n","    out = tf.matmul(out, f_decoder_fc2_w) + f_decoder_fc2_b\n","    out = tf.nn.relu(out)\n","        \n","    return out\n","\n","# f_z\n","f_z_fc1_w = tf.get_variable(\"phi_z_fc1_w\", shape=[latent_dim, latent_dim])\n","f_z_fc2_w = tf.get_variable(\"phi_z_fc2_w\", shape=[latent_dim, latent_dim])\n","\n","f_z_fc1_b = tf.get_variable(\"phi_z_fc1_b\", shape=[latent_dim])\n","f_z_fc2_b = tf.get_variable(\"phi_z_fc2_b\", shape=[latent_dim])\n","\n","def f_z(out):\n","    out = tf.matmul(out, f_z_fc1_w) + f_z_fc1_b\n","    out = tf.nn.relu(out)\n","    out = tf.matmul(out, f_z_fc2_w) + f_z_fc2_b\n","    out = tf.nn.relu(out)\n","    return out\n","\n","# f_prior\n","f_prior_fc1_w = tf.get_variable(\"phi_prior_fc1_w\", shape=[lstm_units, latent_dim])\n","f_prior_fc2_w = tf.get_variable(\"phi_prior_fc2_w\", shape=[latent_dim, latent_dim])\n","\n","f_prior_fc1_b = tf.get_variable(\"phi_prior_fc1_b\", shape=[latent_dim])\n","f_prior_fc2_b = tf.get_variable(\"phi_prior_fc2_b\", shape=[latent_dim])\n","\n","f_prior_mu_w = tf.get_variable(\"phi_prior_mu_w\", shape=[latent_dim, latent_dim])\n","f_prior_std_w = tf.get_variable(\"phi_prior_std_w\", shape=[latent_dim, latent_dim])\n","\n","f_prior_mu_b = tf.get_variable(\"phi_prior_mu_b\", shape=[latent_dim])\n","f_prior_std_b = tf.get_variable(\"phi_prior_std_b\", shape=[latent_dim])\n","\n","def f_prior(out):\n","    out = tf.matmul(out, f_prior_fc1_w) + f_prior_fc1_b\n","    out = tf.nn.relu(out)\n","    out = tf.matmul(out, f_prior_fc2_w) + f_prior_fc2_b\n","    out = tf.nn.relu(out)\n","    \n","    out_mu  = tf.matmul(out, f_prior_mu_w)  + f_prior_mu_b\n","    out_std = tf.nn.softplus(tf.matmul(out, f_prior_std_w) + f_prior_std_b)\n","    \n","    return out_mu, out_std\n","\n","def tf_kl_gaussgauss(mu_1, sigma_1, mu_2, sigma_2):\n","    return tf.reduce_sum(tf.log(sigma_2) - tf.log(sigma_1) + (sigma_1**2 + (mu_1 - mu_2)**2) / (2*((sigma_2)**2)) - 0.5, axis=1)\n","\n","def cross_entropy(y_prediction, y):\n","    prediction_loss = y * tf.log(1e-10 + y_prediction) + (1 - y) * tf.log(1e-10 + 1 - y_prediction)\n","    return -tf.reduce_sum(prediction_loss, axis=[1, 2, 3])   \n","\n","def batch_data(source, target, batch_size):\n","\n","   # Shuffle data\n","    shuffle_indices = np.random.permutation(np.arange(len(target)))\n","    source = source[shuffle_indices]\n","    target = target[shuffle_indices]\n","\n","    for batch_i in range(0, len(source)//batch_size):\n","        start_i = batch_i * batch_size\n","        source_batch = source[start_i:start_i + batch_size]\n","        target_batch = target[start_i:start_i + batch_size]\n","\n","        yield np.array(source_batch), np.array(target_batch)\n","\n","# lstm\n","lstm  = tf.nn.rnn_cell.LSTMCell(num_units = lstm_units, state_is_tuple=True)\n","lstm_state = lstm.zero_state(batch_size, tf.float32)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-6-a8689c2cffff>:154: LSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IHPI6ZB_sY0j"},"source":["# Define Architecture"]},{"cell_type":"code","metadata":{"id":"eeef_GCisY0k","executionInfo":{"status":"ok","timestamp":1602342046382,"user_tz":-480,"elapsed":8695,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"426427f5-d766-412a-c194-5f27220351eb","colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["loss_list = [None]*19\n","kl_divergence_list = [None]*19\n","reconstruction_loss_list = [None]*19\n","    \n","for i in range(0,len(in_timesteps)):\n","    \n","    # encode image\n","    encoder_out = encoder(tf.divide(x=x_[:,i,:,:,:],y=255.0))\n","\n","    # compute prior\n","    f_prior_out_mu, f_prior_out_sigma = f_prior(lstm_state[1])\n","\n","    # compute posterior\n","    f_posterior_out_mu, f_posterior_out_sigma = f_posterior(tf.concat(values=(lstm_state[1], encoder(tf.divide(x=y_[:,i,:,:,:],y=255.0))), axis=1))\n","    \n","    # sample from posterior \n","    z = f_posterior_out_mu + f_posterior_out_sigma * tf.random_normal(shape=[256], mean=0.0, stddev=1.0)        \n","    f_z_out = f_z(z)\n","\n","    # decode [lstm, latent information]\n","    f_decoder_out = f_decoder(tf.concat(values=(lstm_state[1], f_z_out), axis=1)) \n","    y_hat = decoder(f_decoder_out)\n","    \n","    # lstm state transition\n","    lstm_out, lstm_state = lstm(inputs = tf.concat(values=(encoder_out, f_z_out), axis=1), state = lstm_state)\n","        \n","    # track divergence of current timestep\n","    kl_divergence_list[i] = tf_kl_gaussgauss(f_posterior_out_mu, f_posterior_out_sigma, f_prior_out_mu, f_prior_out_sigma)    \n","    tf.summary.scalar(\"kl_divergence_loss_\" + str(i), tf.reduce_mean(kl_divergence_list[i]))\n","                \n","    # track reconstruction loss of current timestep\n","    reconstruction_loss_list[i] = cross_entropy(y_hat,tf.divide(x=y_[:,i,:,:,:],y=255.0))\n","    tf.summary.scalar(\"reconstruction_loss_\" + str(i), tf.reduce_mean(reconstruction_loss_list[i]))\n","         \n","    # track total loss of current timestep\n","    loss_list[i] = tf.reduce_mean(kl_divergence_list[i] + reconstruction_loss_list[i])\n","    tf.summary.scalar(\"total_loss_\" + str(i), loss_list[i])\n","    \n","# optimize loss and track its mean across the 19 timesteps\n","loss = tf.stack(loss_list)\n","optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(loss)\n","tf.summary.scalar(\"total_loss_mean\", tf.reduce_mean(loss))\n","    \n","# track mean of kl divergence across the 19 timesteps\n","kl_divergence = tf.stack(kl_divergence_list)\n","tf.summary.scalar(\"kl_divergence_loss_mean\", tf.reduce_mean(kl_divergence))\n","\n","# track mean of reconstruction loss across the 19 timesteps\n","reconstruction_loss = tf.stack(reconstruction_loss_list)\n","tf.summary.scalar(\"reconstruction_loss_mean\", tf.reduce_mean(reconstruction_loss))\n","    \n","# train and validation counters\n","train_counter = tf.Variable(0, name=\"train_counter\", trainable=False)\n","increment_train_counter = tf.assign(train_counter, train_counter+1)\n","validation_counter = tf.Variable(0, name=\"validation_counter\", trainable=False)\n","increment_validation_counter = tf.assign(validation_counter, train_counter+1)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:966: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:970: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SRf-qM_CsY0p"},"source":["# Begin Training"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"saphurWvsY0q","executionInfo":{"status":"ok","timestamp":1602347797334,"user_tz":-480,"elapsed":5746066,"user":{"displayName":"Yen Siang Leow","photoUrl":"","userId":"11955360749785008998"}},"outputId":"2c7db776-7a3a-479b-a8ee-d0e4c11f060e","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Summaries\n","merged_summary_op = tf.summary.merge_all()\n","train_summary_writer = tf.summary.FileWriter('./train/', graph=tf.get_default_graph())\n","validation_summary_writer = tf.summary.FileWriter('./validation/',graph=tf.get_default_graph())\n","\n","# initialize all variables\n","init = tf.global_variables_initializer()\n","\n","# to save variables\n","saver = tf.train.Saver(max_to_keep=10)\n","\n","# Start a new TF session\n","sess = tf.Session()\n","\n","# Run the initializer\n","sess.run(init)\n","\n","# Train\n","for i in range(1, 101):\n","    \n","    print ('Epoch ', i)\n","    \n","    # Train\n","    for x_tr_batch, y_tr_batch in batch_data(x_tr, y_tr, batch_size=batch_size):\n","        _, step, summary = sess.run([optimizer, increment_train_counter, merged_summary_op], feed_dict={x_: x_tr_batch, y_: y_tr_batch})\n","        train_summary_writer.add_summary(summary, step)     \n","              \n","    # Validate\n","    for x_te_batch, y_te_batch in batch_data(x_te, y_te, batch_size=batch_size):\n","        step, summary = sess.run([increment_validation_counter, merged_summary_op], feed_dict={x_: x_te_batch, y_: y_te_batch}) \n","        validation_summary_writer.add_summary(summary, step)\n","    \n","save_path = saver.save(sess, 'epoch', i)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch  1\n","Epoch  2\n","Epoch  3\n","Epoch  4\n","Epoch  5\n","Epoch  6\n","Epoch  7\n","Epoch  8\n","Epoch  9\n","Epoch  10\n","Epoch  11\n","Epoch  12\n","Epoch  13\n","Epoch  14\n","Epoch  15\n","Epoch  16\n","Epoch  17\n","Epoch  18\n","Epoch  19\n","Epoch  20\n","Epoch  21\n","Epoch  22\n","Epoch  23\n","Epoch  24\n","Epoch  25\n","Epoch  26\n","Epoch  27\n","Epoch  28\n","Epoch  29\n","Epoch  30\n","Epoch  31\n","Epoch  32\n","Epoch  33\n","Epoch  34\n","Epoch  35\n","Epoch  36\n","Epoch  37\n","Epoch  38\n","Epoch  39\n","Epoch  40\n","Epoch  41\n","Epoch  42\n","Epoch  43\n","Epoch  44\n","Epoch  45\n","Epoch  46\n","Epoch  47\n","Epoch  48\n","Epoch  49\n","Epoch  50\n","Epoch  51\n","Epoch  52\n","Epoch  53\n","Epoch  54\n","Epoch  55\n","Epoch  56\n","Epoch  57\n","Epoch  58\n","Epoch  59\n","Epoch  60\n","Epoch  61\n","Epoch  62\n","Epoch  63\n","Epoch  64\n","Epoch  65\n","Epoch  66\n","Epoch  67\n","Epoch  68\n","Epoch  69\n","Epoch  70\n","Epoch  71\n","Epoch  72\n","Epoch  73\n","Epoch  74\n","Epoch  75\n","Epoch  76\n","Epoch  77\n","Epoch  78\n","Epoch  79\n","Epoch  80\n","Epoch  81\n","Epoch  82\n","Epoch  83\n","Epoch  84\n","Epoch  85\n","Epoch  86\n","Epoch  87\n","Epoch  88\n","Epoch  89\n","Epoch  90\n","Epoch  91\n","Epoch  92\n","Epoch  93\n","Epoch  94\n","Epoch  95\n","Epoch  96\n","Epoch  97\n","Epoch  98\n","Epoch  99\n","Epoch  100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ImXraNO20bqb"},"source":[""],"execution_count":null,"outputs":[]}]}